{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>es_numerosa</th>\n",
       "      <th>educacion_madre</th>\n",
       "      <th>educacion_padre</th>\n",
       "      <th>tiempo_viaje</th>\n",
       "      <th>tiempo_estudio</th>\n",
       "      <th>consumo_alcohol_entre_semana</th>\n",
       "      <th>consumo_alcohol_fin_de_semana</th>\n",
       "      <th>suspensos</th>\n",
       "      <th>faltas</th>\n",
       "      <th>nota1</th>\n",
       "      <th>nota2</th>\n",
       "      <th>nota3</th>\n",
       "      <th>educacion_media</th>\n",
       "      <th>notas_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.53125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   es_numerosa  educacion_madre  educacion_padre  tiempo_viaje  \\\n",
       "0          0.0             1.00             0.75           0.0   \n",
       "1          1.0             0.50             0.50           0.5   \n",
       "2          1.0             1.00             0.50           0.5   \n",
       "3          1.0             0.50             0.25           0.5   \n",
       "4          0.0             0.25             0.50           0.5   \n",
       "\n",
       "   tiempo_estudio  consumo_alcohol_entre_semana  \\\n",
       "0             1.0                           0.0   \n",
       "1             1.0                           0.0   \n",
       "2             0.5                           0.0   \n",
       "3             0.5                           0.0   \n",
       "4             0.0                           0.0   \n",
       "\n",
       "   consumo_alcohol_fin_de_semana  suspensos  faltas     nota1  nota2  \\\n",
       "0                            0.0        0.0     0.0  0.615385    0.6   \n",
       "1                            0.0        0.0     0.5  0.615385    0.6   \n",
       "2                            0.0        0.0     0.9  0.384615    0.2   \n",
       "3                            0.2        0.0     0.2  0.461538    0.4   \n",
       "4                            0.6        0.0     0.0  0.615385    0.6   \n",
       "\n",
       "      nota3  educacion_media  notas_media  \n",
       "0  0.583333            0.875      0.62500  \n",
       "1  0.666667            0.500      0.65625  \n",
       "2  0.250000            0.750      0.28125  \n",
       "3  0.666667            0.375      0.53125  \n",
       "4  0.666667            0.375      0.65625  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CSV_FILE = 'EDA/df_normalized.csv'\n",
    "\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de variables inecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n² 94%\n",
    "\n",
    "df = df.drop(\n",
    "    columns = [\n",
    "        'educacion_padre', 'educacion_madre',\n",
    "        'nota1', 'nota2', \n",
    "    ]\n",
    ")\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo notas_media\n",
    "Este modelo se centra en predecir la `nota_media` de un estudiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=['notas_media'])\n",
    "Y_train = train_df[\"notas_media\"]\n",
    "X_test = test_df.drop(columns=['notas_media'])\n",
    "Y_test = test_df[\"notas_media\"]\n",
    "\n",
    "# display(X_train)\n",
    "# display(Y_train)\n",
    "# display(X_test)\n",
    "# display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal es una técnica más que conocida de modelado predictivo que se utiliza para predecir el valor de una variable dependiente (`Y`)  basada en una o más variables independientes (`X`).\n",
    "\n",
    "#### Variables que influyen en el modelo\n",
    "\n",
    "- **Variable Dependiente (Y)**: Es la variable que queremos predecir.\n",
    "- **Variable Independiente (X)**: Son las variables que utilizamos para hacer la predicción.\n",
    "- **Coeficientes (β)**: Representan la relación entre las variables independientes y la variable dependiente.\n",
    "- **Intersección (β0)**: Es el valor de Y cuando todas las variables independientes son cero.\n",
    "\n",
    "#### Fórmula de la Regresión Lineal\n",
    "\n",
    "La ecuación de la regresión lineal simple (con una sola variable independiente) es:\n",
    "\n",
    "\\[ Y = β0 + β1X \\]\n",
    "\n",
    "Para la regresión lineal múltiple (con múltiples variables independientes), la ecuación es:\n",
    "\n",
    "\\[ Y = β0 + β1X1 + β2X2 + ... + βnXn \\]\n",
    "\n",
    "### Ventajas y Desventajas\n",
    "\n",
    "#### Ventajas\n",
    "- **Simplicidad**: Fácil de entender e interpretar.\n",
    "- **Eficiencia**: Rápido de entrenar y predecir.\n",
    "- **Interpretabilidad**: Los coeficientes pueden interpretarse directamente.\n",
    "\n",
    "#### Desventajas\n",
    "- **Linealidad**: Asume una relación lineal entre las variables independientes y dependientes.\n",
    "- **Sensibilidad a Outliers**: Los valores atípicos pueden influir significativamente en el modelo.\n",
    "- **Multicolinealidad**: La presencia de alta correlación entre las variables independientes puede afectar la estabilidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo\n",
    "lr_reg = LinearRegression()\n",
    "\n",
    "# Definimos los hiperámetros dentro del diccionario param_grid\n",
    "# Este será udano por \n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "# La instacia de GridSearchCV sirve para hacer una búsqueda \n",
    "# Estensiva sobre los diferentes hiperparámtros especificados en param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    # Modelo elegido\n",
    "    lr_reg,\n",
    "    # Hiperparaḿetros\n",
    "    param_grid=param_grid,\n",
    "    # Número de cruces para la validación cruzada\n",
    "    cv=5,\n",
    "    # Métrica evaluación modelo\n",
    "    scoring='r2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Escogemos las méjores métricas\n",
    "best_lr_reg = grid_search.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "Y_pred = best_lr_reg.predict(X_test)\n",
    "\n",
    "# Otras métricas útiles\n",
    "mae_lr = mean_absolute_error(Y_test, Y_pred)\n",
    "mse_lr = mean_squared_error(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámteos: {'copy_X': True, 'fit_intercept': False, 'positive': False}\n",
      "Mejor resultado validación cruzada (R²): 0.9387\n",
      "MAE (Error absoluto medio): 0.0475\n",
      "MSE (Error cuadrático medio): 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las métricas de validación cruzada\n",
    "print(f'Mejores parámteos: {grid_search.best_params_}')\n",
    "print(f'Mejor resultado validación cruzada (R²): {grid_search.best_score_:.4f}')\n",
    "\n",
    "# Otras métricas\n",
    "print(f'MAE (Error absoluto medio): {mae_lr:.4f}')\n",
    "print(f'MSE (Error cuadrático medio): {mse_lr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting** es un método de aprendizaje automático que combina múltiples modelos simples (o débiles) para crear un modelo predictivo fuerte.\n",
    "\n",
    "#### Datos de Entrada\n",
    "\n",
    "1. **Características (X):** Variables predictoras del modelo. Pueden ser numéricas o categóricas.\n",
    "2. **Etiqueta (Y):** Variable objetivo que se desea predecir. Puede ser continua (para regresión) o categórica (para clasificación).\n",
    "\n",
    "#### Fórmula Básica\n",
    "\n",
    "El modelo predictivo final se construye iterativamente sumando modelos simples ajustados al error residual. La fórmula general es:\n",
    "\n",
    "\\[\n",
    "F_m(x) = F_{m-1}(x) + \\eta \\cdot h_m(x)\n",
    "\\]\n",
    "\n",
    "Donde:\n",
    "- \\( F_m(x) \\): Modelo en la iteración \\( m \\).\n",
    "- \\( F_{m-1}(x) \\): Modelo acumulado hasta la iteración \\( m-1 \\).\n",
    "- \\( \\eta \\): Tasa de aprendizaje que controla la contribución de cada modelo.\n",
    "- \\( h_m(x) \\): Modelo ajustado al error residual en la iteración \\( m \\).\n",
    "\n",
    "#### Ventajas\n",
    "\n",
    "- **Precisión:** Generalmente proporciona alta precisión en comparación con otros métodos.\n",
    "- **Flexibilidad:** Puede manejar diferentes tipos de datos y problemas.\n",
    "- **No requiere normalización:** Los datos no necesitan ser normalizados.\n",
    "\n",
    "#### Desventajas\n",
    "\n",
    "- **Tiempo de Entrenamiento:** Puede ser lento debido a la naturaleza iterativa del algoritmo.\n",
    "- **Complejidad:** Puede ser más complejo de entender y ajustar en comparación con otros métodos.\n",
    "- **Sobreajuste:** Puede sobreajustarse si no se controla adecuadamente.\n",
    "\n",
    "#### Parámetros Clave\n",
    "\n",
    "- `n_estimators`: Número de árboles en el modelo.\n",
    "- `learning_rate`: Tasa de aprendizaje que controla el peso de cada árbol.\n",
    "- `max_depth`: Profundidad máxima de cada árbol.\n",
    "\n",
    "##### Referencia\n",
    "Scikit-learn. (n.d.). GradientBoostingClassifier. Scikit-learn Documentation. Retrieved December 6, 2024, from https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el espacio de parámetros\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda en cuadrícula\n",
    "grid_search_gb = GridSearchCV(\n",
    "    GradientBoostingRegressor(),\n",
    "    param_grid=param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar la búsqueda en cuadrícula\n",
    "grid_search_gb.fit(X_train, Y_train)\n",
    "\n",
    "# Obtener las mejores estimaciones\n",
    "best_gb_reg = grid_search_gb.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "Y_pred_best_gb = best_gb_reg.predict(X_test)\n",
    "\n",
    "# Otras métricas interesantas\n",
    "mae_best_gb = mean_absolute_error(Y_test, Y_pred_best_gb)\n",
    "mse_best_gb = mean_squared_error(Y_test, Y_pred_best_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Mejor resultado con validación cruzada (métrica R²): 0.9318\n",
      "MAE (Error absoluto medio): 0.0488\n",
      "MSE (Error cuadrático medio): 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las métricas\n",
    "print(f'Mejores hiperparámetros encontrados: {grid_search_gb.best_params_}')\n",
    "print(f'Mejor resultado con validación cruzada (métrica R²): {grid_search_gb.best_score_:.4f}')\n",
    "print(f'MAE (Error absoluto medio): {mae_best_gb:.4f}')\n",
    "print(f'MSE (Error cuadrático medio): {mse_best_gb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression** es una técnica de aprendizaje supervisado que extiende la regresión lineal al añadir un término de penalización. Este término ayuda a reducir el sobreajuste y mejora la capacidad de generalización del modelo al restringir los coeficientes de las características.\n",
    "\n",
    "#### Funcionamiento\n",
    "\n",
    "Ridge Regression minimiza una función de pérdida que combina el error cuadrático medio y una penalización L2 sobre los coeficientes. La fórmula general es:\n",
    "\n",
    "\n",
    "\\[\n",
    "\\text{Error} = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\alpha \\cdot \\sum_{j=1}^{p}\\beta_j^2\n",
    "\\]\n",
    "\n",
    "Donde:\n",
    "- \\( y_i \\): Valores reales de la variable objetivo.\n",
    "- \\( \\hat{y}_i \\): Predicciones del modelo.\n",
    "- \\( \\beta_j \\): Coeficientes de las características.\n",
    "- \\( \\alpha \\): Parámetro de regularización que controla la penalización (cuanto mayor sea \\( \\alpha \\), mayor será la regularización).\n",
    "\n",
    "#### Parámetros Clave\n",
    "\n",
    "1. **`alpha`**: Controla la intensidad de la regularización.\n",
    "   - Un valor mayor de `alpha` aplica una penalización más fuerte.\n",
    "   - Un valor menor de `alpha` se acerca a una regresión lineal estándar.\n",
    "   \n",
    "2. **`fit_intercept`**: Determina si se ajusta un término independiente (intercepto) en el modelo.\n",
    "   \n",
    "3. **`normalize`**: Si es `True`, las características se normalizan antes de ajustar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1.0, 10.0],\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_ridge = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid=param_grid_ridge,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridge.fit(X_train, Y_train)\n",
    "\n",
    "best_ridge_grid = grid_search_ridge.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "Y_pred_ridge_grid = best_ridge_grid.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "mae_ridge_grid = mean_absolute_error(Y_test, Y_pred_ridge_grid)\n",
    "mse_ridge_grid = mean_squared_error(Y_test, Y_pred_ridge_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hipeparámetros: {'alpha': 0.1, 'copy_X': True, 'fit_intercept': False, 'positive': False}\n",
      "Mejor resultado con validación cruzada (métrica R²): 0.9384\n",
      "MAE (Error absoluto medio): 0.0476\n",
      "MSE (Error cuadrático medio): 0.0037\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las métricas de validación cruzada\n",
    "print(f'Mejores hipeparámetros: {grid_search_ridge.best_params_}')\n",
    "print(f'Mejor resultado con validación cruzada (métrica R²): {grid_search_ridge.best_score_:.4f}')\n",
    "print(f'MAE (Error absoluto medio): {mae_ridge_grid:.4f}')\n",
    "print(f'MSE (Error cuadrático medio): {mse_ridge_grid:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR)\n",
    "\n",
    "**Support Vector Regression (SVR)** es una técnica de aprendizaje supervisado basada en máquinas de soporte vectorial (**SVM**) que se utiliza para problemas de regresión. Su objetivo es encontrar una función que tenga, al mismo tiempo, la mayor simplicidad y el menor error dentro de un margen tolerable definido por el usuario.\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Margen de tolerancia (\\(\\epsilon\\))**:\n",
    "   - SVR permite que los errores de predicción dentro de un margen definido (\\(\\epsilon\\)) no sean penalizados.\n",
    "   - Cualquier error fuera de este margen sí se penaliza.\n",
    "\n",
    "2. **Optimización**:\n",
    "   - Busca minimizar una función de pérdida basada en el margen de tolerancia y un término de regularización que controla la complejidad del modelo.\n",
    "   - La solución se define en términos de un subconjunto de los puntos de datos llamados **vectores de soporte**.\n",
    "\n",
    "#### Fórmula Básica\n",
    "\n",
    "El objetivo de SVR es resolver el siguiente problema de optimización:\n",
    "\n",
    "\\[\n",
    "\\min_{w, b} \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^n (\\xi_i + \\xi_i^*)\n",
    "\\]\n",
    "\n",
    "Sujeto a las restricciones:\n",
    "\\[\n",
    "y_i - (w^T x_i + b) \\leq \\epsilon + \\xi_i\n",
    "\\]\n",
    "\\[\n",
    "(w^T x_i + b) - y_i \\leq \\epsilon + \\xi_i^*\n",
    "\\]\n",
    "\\[\n",
    "\\xi_i, \\xi_i^* \\geq 0\n",
    "\\]\n",
    "\n",
    "Donde:\n",
    "- \\( w \\): Vector de pesos.\n",
    "- \\( b \\): Término independiente.\n",
    "- \\( C \\): Parámetro de regularización que controla el equilibrio entre el error tolerado y la simplicidad del modelo.\n",
    "- \\( \\xi_i, \\xi_i^* \\): Variables de holgura que permiten errores fuera del margen.\n",
    "- \\( \\epsilon \\): Margen de tolerancia.\n",
    "\n",
    "#### Ventajas\n",
    "\n",
    "- **Control de Complejidad**: Gracias al parámetro \\(C\\), se puede ajustar el equilibrio entre simplicidad del modelo y error.\n",
    "- **No Linealidad**: A través del uso de kernels, SVR puede capturar relaciones no lineales en los datos.\n",
    "- **Robustez**: Es menos propenso al sobreajuste en comparación con otros métodos de regresión, especialmente en conjuntos de datos pequeños.\n",
    "\n",
    "#### Desventajas\n",
    "\n",
    "- **Sensibilidad a los Parámetros**: La selección de \\(C\\), \\(\\epsilon\\) y el tipo de kernel afecta significativamente el rendimiento.\n",
    "- **Coste Computacional**: Para grandes conjuntos de datos, puede ser más lento en comparación con otros métodos.\n",
    "- **Interpretabilidad**: Los modelos basados en kernels pueden ser difíciles de interpretar.\n",
    "\n",
    "\n",
    "#### Parámetros Clave\n",
    "\n",
    "1. **`kernel`**: Define la función de kernel utilizada para proyectar los datos a un espacio de características más alto. Los más comunes son:\n",
    "   - `linear`\n",
    "   - `poly`\n",
    "   - `rbf` (Radial Basis Function)\n",
    "   - `sigmoid`\n",
    "\n",
    "2. **`C`**: Parámetro de regularización que controla el trade-off entre simplicidad del modelo y tolerancia al error.\n",
    "\n",
    "3. **`epsilon`**: Define el margen de tolerancia donde los errores no se penalizan.\n",
    "\n",
    "4. **`gamma`**: Utilizado en kernels no lineales como `rbf` y `poly` para controlar la influencia de un solo punto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el espacio de parámetros\n",
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.2],\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Configurar la búsqueda en cuadrícula\n",
    "grid_search_svr = GridSearchCV(\n",
    "    SVR(),\n",
    "    param_grid=param_grid_svr,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svr.fit(X_train, Y_train)\n",
    "best_svr = grid_search_svr.best_estimator_\n",
    "\n",
    "# Predecir\n",
    "Y_pred_svr = best_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados: {'C': 1, 'epsilon': 0.01, 'kernel': 'linear'}\n",
      "Mejor resultado con validación cruzada (métrica R²): 0.9372\n",
      "MAE (Error absoluto medio): 0.0476\n",
      "MSE (Error cuadrático medio): 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Evaluación\n",
    "mae_svr = mean_absolute_error(Y_test, Y_pred_svr)\n",
    "mse_svr = mean_squared_error(Y_test, Y_pred_svr)\n",
    "\n",
    "# Mostrar las métricas de validación cruzada\n",
    "print(f'Mejores hiperparámetros encontrados: {grid_search_svr.best_params_}')\n",
    "print(f'Mejor resultado con validación cruzada (métrica R²): {grid_search_svr.best_score_:.4f}')\n",
    "print(f'MAE (Error absoluto medio): {mae_svr:.4f}')\n",
    "print(f'MSE (Error cuadrático medio): {mse_svr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: SVR, R²: 0.9297\n",
      "Modelo: Linear Regression, R²: 0.9293\n",
      "Modelo: Ridge Regression, R²: 0.9285\n",
      "Modelo: Gradient Boosting, R²: 0.9252\n"
     ]
    }
   ],
   "source": [
    "# Calcular el R² para cada modelo\n",
    "r2_lr = grid_search.score(X_test, Y_test)\n",
    "r2_gb = grid_search_gb.score(X_test, Y_test)\n",
    "r2_ridge = grid_search_ridge.score(X_test, Y_test)\n",
    "r2_svr = grid_search_svr.score(X_test, Y_test)\n",
    "\n",
    "# Ordenar los modelos de mejor a peor basado en R²\n",
    "model_scores = [\n",
    "    ('Linear Regression', r2_lr), \n",
    "    ('Gradient Boosting', r2_gb), \n",
    "    ('Ridge Regression', r2_ridge), \n",
    "    ('SVR', r2_svr)\n",
    "]\n",
    "\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Imprimir los modelos ordenados\n",
    "for model_name, r2_score in sorted_models:\n",
    "    print(f'Modelo: {model_name}, R²: {r2_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que todos los modelos presentan valores de R² muy similares. Esto implica que no podemos basarnos únicamente en esta métrica para elegir el mejor modelo.\n",
    "\n",
    "Además, la elección del modelo óptimo puede variar entre iteraciones debido a la influencia de diferentes factores o estrategias heurísticas utilizadas durante el proceso. Esto significa que un modelo que fue considerado el mejor en una ejecución podría no serlo en otra, como ya se ha comprobado en análisis previos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las carpetas si no existen\n",
    "directorios = [\n",
    "    'Persistencia',\n",
    "    'Persistencia/Regresion',\n",
    "    'Persistencia/Clasificacion',\n",
    "    'Persistencia/clusterizacion',\n",
    "]\n",
    "\n",
    "for directorio in directorios:\n",
    "    if not os.path.exists(directorio):\n",
    "        os.makedirs(directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los mejores modelos\n",
    "joblib.dump(best_lr_reg, 'Persistencia/Regresion/lr.pkl')\n",
    "joblib.dump(best_gb_reg, 'Persistencia/Regresion/gb.pkl')\n",
    "joblib.dump(best_ridge_grid, 'Persistencia/Regresion/ridge.pkl')\n",
    "joblib.dump(best_svr, 'Persistencia/Regresion/svr.pkl')\n",
    "\n",
    "# Guardar los conjuntos de datos\n",
    "df.to_csv('Persistencia/Regresion/df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
